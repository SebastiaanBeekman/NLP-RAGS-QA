{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from transformers import PreTrainedModel, AutoConfig, AutoModel, AutoTokenizer\n",
    "from typing import List, Optional, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Turn off parallelism for tokenizers from Hugging Face\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# General variables\n",
    "seed = int(os.getenv(\"SEED\"))\n",
    "batch_size = int(os.getenv(\"BATCH_SIZE\"))\n",
    "save_every = int(os.getenv(\"SAVE_EVERY\"))\n",
    "\n",
    "# Embeddings variables\n",
    "corpus_path = os.getenv(\"CORPUS_PATH\")\n",
    "max_length_encoder = int(os.getenv(\"MAX_LENGTH_ENCODER\"))\n",
    "normalize_embeddings = os.getenv(\"NORMALIZE_EMBEDDINGS\") == \"True\"\n",
    "lower_case = os.getenv(\"LOWER_CASE\") == \"True\"\n",
    "normalize_text = os.getenv(\"NORMALIZE_TEXT\") == \"True\"\n",
    "embeddings_dir = os.getenv(\"EMBEDDINGS_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def read_json(file_path: str):\n",
    "    with open(file_path, \"rb\") as reader:\n",
    "        data = json.load(reader)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_json(data, file_path: str):\n",
    "    with open(file_path, \"w\") as writer:\n",
    "        json.dump(data, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run seeder before proceeding\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    A wrapper class for encoding text using pre-trained transformer models with specified pooling strategy.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: AutoConfig, pooling: str = \"average\"):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        if not hasattr(self.config, \"pooling\"):\n",
    "            self.config.pooling = pooling\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            config.name_or_path, config=self.config\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "    \n",
    "    def encode(\n",
    "        self, \n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        normalize: bool = False\n",
    "    ) -> torch.Tensor:\n",
    "        model_output = self.forward(\n",
    "            input_ids, \n",
    "            attention_mask,\n",
    "            token_type_ids,\n",
    "        )\n",
    "        last_hidden = model_output[\"last_hidden_state\"]\n",
    "        last_hidden = last_hidden.masked_fill(~attention_mask[..., None].bool(), 0.)\n",
    "\n",
    "        if self.config.pooling == \"average\":\n",
    "            emb = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        elif self.config.pooling == \"cls\":\n",
    "            emb = last_hidden[:, 0]\n",
    "\n",
    "        if normalize:\n",
    "            emb = F.normalize(emb, dim=-1)\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    \"\"\"\n",
    "    A class for retrieving document embeddings using a specified encoder, using a bi-encoder approach.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        query_encoder: Encoder,\n",
    "        doc_encoder: Optional[Encoder] = None,\n",
    "        max_length: int = 512,\n",
    "        add_special_tokens: bool = True,\n",
    "        norm_query_emb: bool = False,\n",
    "        norm_doc_emb: bool = False,\n",
    "        lower_case: bool = False,\n",
    "        do_normalize_text: bool = False,\n",
    "    ):\n",
    "        \n",
    "        self.device = device\n",
    "        self.query_encoder = query_encoder.to(device)\n",
    "        self.doc_encoder = self.query_encoder if doc_encoder is None else doc_encoder.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.add_special_tokens = add_special_tokens\n",
    "        self.norm_query_emb = norm_query_emb\n",
    "        self.norm_doc_emb = norm_doc_emb\n",
    "        self.lower_case = lower_case\n",
    "        self.do_normalize_text = do_normalize_text\n",
    "    \n",
    "\n",
    "    def encode_corpus(\n",
    "        self, \n",
    "        corpus_info: List[Dict[str, str]], \n",
    "        batch_size: int, \n",
    "        embeddings_dir: str, \n",
    "        save_every: int = 500\n",
    "    ) -> None:\n",
    "        os.makedirs(embeddings_dir, exist_ok=True)\n",
    "        \n",
    "        all_embeddings = []\n",
    "        num_steps = 0\n",
    "\n",
    "        nbatch = (len(corpus_info) - 1) // batch_size + 1\n",
    "        print(f\"Total number of batches: {nbatch}\")\n",
    "        with torch.no_grad():\n",
    "            for k in tqdm(range(nbatch)):\n",
    "                start_idx = k * batch_size\n",
    "                end_idx = min((k + 1) * batch_size, len(corpus_info))\n",
    "                # print(f\"Start index: {start_idx}, End index: {end_idx}\")\n",
    "\n",
    "                corpus = [\n",
    "                    c[\"title\"] + \" \" + c[\"text\"] if len(c[\"title\"]) > 0 else c[\"text\"] \n",
    "                    for c in corpus_info[start_idx: end_idx]\n",
    "                ]\n",
    "                if self.do_normalize_text:\n",
    "                    corpus = [normalize_text.normalize(c) for c in corpus]\n",
    "                if self.lower_case:\n",
    "                    corpus = [c.lower() for c in corpus]\n",
    "\n",
    "                doc_inputs = self.tokenizer(\n",
    "                    corpus,\n",
    "                    max_length=self.max_length,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    add_special_tokens=self.add_special_tokens,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(self.device)\n",
    "\n",
    "                emb = self.doc_encoder.encode(**doc_inputs, normalize=self.norm_doc_emb)\n",
    "                all_embeddings.append(emb)\n",
    "\n",
    "                num_steps += 1\n",
    "\n",
    "                if num_steps == save_every or k == nbatch - 1:\n",
    "                    embeddings = torch.cat(all_embeddings, dim=0)\n",
    "                    file_index = end_idx - 1  # Index of the last passage embedded in the batch\n",
    "                    file_path = os.path.join(\n",
    "                        embeddings_dir, f'{file_index}_embeddings.npy'\n",
    "                    )\n",
    "                    np.save(file_path, embeddings.cpu().numpy())\n",
    "                    print(f\"Saved embeddings for {file_index} passages.\")\n",
    "                    num_steps = 0\n",
    "                    all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_retriever() -> Retriever:\n",
    "    config = AutoConfig.from_pretrained(\"facebook/contriever\")\n",
    "    encoder = Encoder(config).eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/contriever\")\n",
    "    retriever = Retriever(\n",
    "        device=device, tokenizer=tokenizer, \n",
    "        query_encoder=encoder, \n",
    "        max_length=max_length_encoder,\n",
    "        norm_doc_emb=normalize_embeddings,\n",
    "        lower_case=lower_case,\n",
    "        do_normalize_text=normalize_text\n",
    "    )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(read_json(corpus_path).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"facebook/contriever\",\n",
      "  \"architectures\": [\n",
      "    \"Contriever\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retriever = initialize_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.encode_corpus(\n",
    "    corpus, \n",
    "    batch_size=batch_size, \n",
    "    embeddings_dir=embeddings_dir,\n",
    "    save_every=save_every\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raspy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
