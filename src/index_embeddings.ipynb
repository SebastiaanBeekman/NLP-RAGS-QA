{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import faiss\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# General variables\n",
    "seed = int(os.getenv(\"SEED\"))\n",
    "batch_size = int(os.getenv(\"BATCH_SIZE\"))\n",
    "save_every = int(os.getenv(\"SAVE_EVERY\"))\n",
    "\n",
    "# Embedding variables\n",
    "embeddings_dir = os.getenv(\"EMBEDDINGS_DIR\")\n",
    "\n",
    "# Indexing variables\n",
    "corpus_size = int(os.getenv(\"CORPUS_SIZE\"))\n",
    "vector_size = int(os.getenv(\"VECTOR_SIZE\"))\n",
    "faiss_dir = os.getenv(\"FAISS_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def read_pickle(file_path: str):\n",
    "    with open(file_path, \"rb\") as reader:\n",
    "        data = pickle.load(reader)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_pickle(data, file_path: str):\n",
    "    with open(file_path, \"wb\") as writer:\n",
    "        pickle.dump(data, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run seeder before proceeding\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings are stored in multiple files due to batch size, this function saves all embeddings into a single file\n",
    "def load_all_embeddings() -> np.array:\n",
    "    all_embeddings_path = f'{embeddings_dir}/all_embeddings.npy'\n",
    "\n",
    "    # Check if the file with all embeddings already exists and in case load it\n",
    "    if os.path.isfile(all_embeddings_path):\n",
    "        embeddings = np.load(all_embeddings_path, mmap_mode='c')\n",
    "        return embeddings\n",
    "\n",
    "    all_embeddings = []\n",
    "    num_embed = batch_size * save_every\n",
    "\n",
    "    for i in range(num_embed - 1, corpus_size, num_embed):\n",
    "        emb_path = f'{embeddings_dir}/{i}_embeddings.npy'\n",
    "        emb = np.load(emb_path, mmap_mode='c')\n",
    "        all_embeddings.append(emb)\n",
    "\n",
    "    last_idx = corpus_size - 1\n",
    "    last_emb_path = f'{embeddings_dir}/{last_idx}_embeddings.npy'\n",
    "    last_emb = np.load(last_emb_path, mmap_mode='c')\n",
    "    all_embeddings.append(last_emb)\n",
    "\n",
    "    embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    np.save(all_embeddings_path, embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings for indexer\n",
    "embeddings = load_all_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer(object):\n",
    "    def __init__(self, vector_size: int):     \n",
    "        self.index = faiss.IndexFlatIP(vector_size)\n",
    "        self.index_id_to_db_id = []\n",
    "\n",
    "\n",
    "    def index_data(self, ids: List[int], embeddings: np.array):\n",
    "        \"\"\"\n",
    "        Adds data to the index.\n",
    "\n",
    "        Args:\n",
    "            ids (List[int]): A list of database IDs corresponding to the embeddings.\n",
    "            embeddings (np.array): A numpy array of embeddings to be indexed.\n",
    "        \"\"\"\n",
    "        self._update_id_mapping(ids)\n",
    "        # embeddings = embeddings.astype('float32')\n",
    "        if not self.index.is_trained:\n",
    "            self.index.train(embeddings)\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "        print(f'Total data indexed {len(self.index_id_to_db_id)}')\n",
    "\n",
    "    def search_knn(\n",
    "        self, \n",
    "        query_vectors: np.array, \n",
    "        top_docs: int, \n",
    "        index_batch_size: int = 2048\n",
    "    ) -> List[Tuple[List[str], List[float]]]:\n",
    "        \"\"\"\n",
    "        Performs a k-nearest neighbor search for the given query vectors.\n",
    "\n",
    "        Args:\n",
    "            query_vectors (np.array): A numpy array of query vectors.\n",
    "            top_docs (int): The number of top documents to return for each query.\n",
    "            index_batch_size (int): The batch size to use when indexing.\n",
    "        \n",
    "        Returns:\n",
    "            A list of tuples, each containing a list of document IDs and a list of corresponding scores.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        nbatch = (len(query_vectors)-1) // index_batch_size + 1\n",
    "        for k in range(nbatch):\n",
    "            start_idx = k*index_batch_size\n",
    "            end_idx = min((k+1)*index_batch_size, len(query_vectors))\n",
    "            q = query_vectors[start_idx: end_idx]\n",
    "            scores, indexes = self.index.search(q, top_docs)\n",
    "            # convert to external ids\n",
    "            db_ids = [[str(self.index_id_to_db_id[i]) for i in query_top_idxs] for query_top_idxs in indexes]\n",
    "            result.extend([(db_ids[i], scores[i]) for i in range(len(db_ids))])\n",
    "        return result\n",
    "\n",
    "    def serialize(\n",
    "        self, \n",
    "        dir_path: str, \n",
    "        index_file_name: Optional[str] = None, \n",
    "        meta_file_name: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Serializes the index and its metadata to disk.\n",
    "\n",
    "        Args:\n",
    "            dir_path (str): The directory path to save the serialized index and metadata.\n",
    "            index_file_name (Optional[str]): Optional custom name for the index file.\n",
    "            meta_file_name (Optional[str]): Optional custom name for the metadata file.\n",
    "        \"\"\"\n",
    "        if index_file_name is None:\n",
    "            index_file_name = 'index.faiss'\n",
    "        if meta_file_name is None:\n",
    "            meta_file_name = 'index_meta.faiss'\n",
    "\n",
    "        index_file = os.path.join(dir_path, index_file_name)\n",
    "        meta_file = os.path.join(dir_path, meta_file_name)\n",
    "        print(f'Serializing index to {index_file}, meta data to {meta_file}')\n",
    "\n",
    "        faiss.write_index(self.index, index_file)\n",
    "        write_pickle(self.index_id_to_db_id, meta_file)\n",
    "\n",
    "\n",
    "    def deserialize_from(\n",
    "        self, \n",
    "        dir_path: str, \n",
    "        index_file_name: Optional[str] = None, \n",
    "        meta_file_name: Optional[str] = None,\n",
    "        gpu_id: Optional[int] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Loads the index and its metadata from disk.\n",
    "\n",
    "        Args:\n",
    "            dir_path (str): The directory path from where to load the index and metadata.\n",
    "            index_file_name (Optional[str]): Optional custom name for the index file.\n",
    "            meta_file_name (Optional[str]): Optional custom name for the metadata file.\n",
    "        \"\"\"\n",
    "        if index_file_name is None:\n",
    "            index_file_name = 'index.faiss'\n",
    "        if meta_file_name is None:\n",
    "            meta_file_name = 'index_meta.faiss'\n",
    "\n",
    "        index_file = os.path.join(dir_path, index_file_name)\n",
    "        meta_file = os.path.join(dir_path, meta_file_name)\n",
    "        print(f'Loading index from {index_file}, meta data from {meta_file}')\n",
    "\n",
    "        self.index = faiss.read_index(index_file)\n",
    "        print(f'Loaded index of type {type(self.index)} and size {self.index.ntotal}')\n",
    "\n",
    "        self.index_id_to_db_id = read_pickle(meta_file)\n",
    "        assert len(\n",
    "            self.index_id_to_db_id) == self.index.ntotal, 'Deserialized index_id_to_db_id should match faiss index size'\n",
    "        \n",
    "        # Move index to GPU if specified\n",
    "        if gpu_id is not None:\n",
    "            res = faiss.StandardGpuResources()  \n",
    "            self.index_gpu = faiss.index_cpu_to_gpu(res, gpu_id , self.index)\n",
    "            del self.index\n",
    "            self.index = self.index_gpu\n",
    "            print(f'Moved index to GPU {gpu_id}')\n",
    "        \n",
    "\n",
    "    def _update_id_mapping(self, db_ids: List[int]):\n",
    "        self.index_id_to_db_id.extend(db_ids)\n",
    "\n",
    "    def get_index_name(self):\n",
    "        return \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing_embeddings(embeddings: np.array) -> None:\n",
    "    os.makedirs(faiss_dir, exist_ok=True)\n",
    "\n",
    "    index = Indexer(vector_size)\n",
    "    index.index_data(list(range(corpus_size)), embeddings)\n",
    "\n",
    "    index.serialize(\n",
    "        dir_path=faiss_dir, \n",
    "        index_file_name=f'index.faiss', \n",
    "        meta_file_name=f'index_meta.faiss'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_embeddings(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raspy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
