# General variables
SEED = 42
BATCH_SIZE = 64
SAVE_EVERY = 500

# Embeddings variables
CORPUS_PATH = "../data/corpus.json"
MAX_LENGTH_ENCODER = 512
NORMALIZE_EMBEDDINGS = False
LOWER_CASE = False
NORMALIZE_TEXT = False
EMBEDDINGS_DIR = "../data/embeddings/"

# Indexing variables
CORPUS_SIZE = -1
VECTOR_SIZE = 768
FAISS_DIR = "../data/embeddings/indexes/"

# Retrieval variables
TOP_K = 5
USE_GPU = False
GPU_IDS = "0, 1"
INDEX_BATCH_SIZE = 64
QUERIES_PATH = '../data/dev_1200.json'
SEARCH_DIR = "../data/retrieval/"

# LLM variables
HF_ACCESS_TOKEN = "" # Please accept the policy on https://huggingface.co/meta-llama/Llama-2-7b-chat-hf when using the Llama model
LLM_ID = "meta-llama/Llama-2-7b-chat-hf"
MAX_INPUT_LENGTH = 4096
MAX_OUTPUT_LENGTH = 15 # Number of tokens in the response
NORMALIZE_QUERIES = False
CONTEXT_RETRIEVAL_DIR = "../data/retrieval/search_results_at_1.pkl"
LLM_RESPONSE_DIR = "../data/llm_responses/"

# Evaluation variables
EVALUATION_DIR = "../data/evaluation/"